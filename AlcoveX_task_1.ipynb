{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "N.V.Nithin Kumar\n",
        "\n",
        "\n",
        "vnamburi@gitam.in"
      ],
      "metadata": {
        "id": "1B44C7elycNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors** - Tensors represent deep learning data. They are multidimensional arrays, used to store multiple dimensions of a dataset. Each dimension is called a feature. For example, a cube storing data across an X, Y, and Z access is represented as a 3-dimensional tensor. Tensors can store very high dimensionality, with hundreds of dimensions of features typically used in deep learning applications."
      ],
      "metadata": {
        "id": "Rs5f3Mas00dG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUIzFcywxCFQ"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the text data\n",
        "text = open('/content/pg5200.txt').read()"
      ],
      "metadata": {
        "id": "ws-U93KkxMeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "encoded = tokenizer.texts_to_sequences([text])[0]"
      ],
      "metadata": {
        "id": "yrIdWGOPxkjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training data\n",
        "sequences = []\n",
        "for i in range(1, len(encoded)):\n",
        "    sequence = encoded[i-1:i+3]\n",
        "    sequences.append(sequence)\n",
        "X = []\n",
        "y = []\n",
        "for seq in sequences:\n",
        "    X.append(seq[:-1])\n",
        "    y.append(seq[-1])\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=3)\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "NNIYz8wyxskV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64, input_length=3),\n",
        "    tf.keras.layers.LSTM(128),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(len(tokenizer.word_index)+1, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "WX4sLolDxwm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fwIWdD4AyB8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(X, y, epochs=25, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-51G9LtyGRz",
        "outputId": "2cadaa89-a414-4b59-d004-e90e8d41d71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "791/791 [==============================] - 18s 16ms/step - loss: 6.4199 - accuracy: 0.0521\n",
            "Epoch 2/25\n",
            "791/791 [==============================] - 13s 17ms/step - loss: 6.0637 - accuracy: 0.0526\n",
            "Epoch 3/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 5.9044 - accuracy: 0.0590\n",
            "Epoch 4/25\n",
            "791/791 [==============================] - 14s 17ms/step - loss: 5.6735 - accuracy: 0.0818\n",
            "Epoch 5/25\n",
            "791/791 [==============================] - 14s 17ms/step - loss: 5.3985 - accuracy: 0.1080\n",
            "Epoch 6/25\n",
            "791/791 [==============================] - 14s 18ms/step - loss: 5.1786 - accuracy: 0.1220\n",
            "Epoch 7/25\n",
            "791/791 [==============================] - 14s 18ms/step - loss: 4.9979 - accuracy: 0.1341\n",
            "Epoch 8/25\n",
            "791/791 [==============================] - 15s 19ms/step - loss: 4.8298 - accuracy: 0.1474\n",
            "Epoch 9/25\n",
            "791/791 [==============================] - 16s 20ms/step - loss: 4.6684 - accuracy: 0.1568\n",
            "Epoch 10/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 4.5220 - accuracy: 0.1663\n",
            "Epoch 11/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 4.3813 - accuracy: 0.1766\n",
            "Epoch 12/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 4.2373 - accuracy: 0.1866\n",
            "Epoch 13/25\n",
            "791/791 [==============================] - 12s 15ms/step - loss: 4.1020 - accuracy: 0.1985\n",
            "Epoch 14/25\n",
            "791/791 [==============================] - 13s 17ms/step - loss: 3.9608 - accuracy: 0.2127\n",
            "Epoch 15/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 3.8193 - accuracy: 0.2249\n",
            "Epoch 16/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 3.6900 - accuracy: 0.2368\n",
            "Epoch 17/25\n",
            "791/791 [==============================] - 13s 17ms/step - loss: 3.5531 - accuracy: 0.2520\n",
            "Epoch 18/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 3.4219 - accuracy: 0.2660\n",
            "Epoch 19/25\n",
            "791/791 [==============================] - 13s 17ms/step - loss: 3.2957 - accuracy: 0.2822\n",
            "Epoch 20/25\n",
            "791/791 [==============================] - 13s 17ms/step - loss: 3.1771 - accuracy: 0.2953\n",
            "Epoch 21/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 3.0552 - accuracy: 0.3134\n",
            "Epoch 22/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 2.9442 - accuracy: 0.3271\n",
            "Epoch 23/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 2.8403 - accuracy: 0.3442\n",
            "Epoch 24/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 2.7466 - accuracy: 0.3619\n",
            "Epoch 25/25\n",
            "791/791 [==============================] - 13s 16ms/step - loss: 2.6546 - accuracy: 0.3767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_text = \"How about if I sleep a\"\n",
        "tokenized_text = tokenizer.texts_to_sequences([test_text])[0]\n",
        "encoded_text = tf.keras.preprocessing.sequence.pad_sequences([tokenized_text], maxlen=3)\n",
        "predicted_probs = model.predict(encoded_text)[0]\n",
        "predicted_word_index = tf.argmax(predicted_probs).numpy()\n",
        "predicted_word = tokenizer.index_word[predicted_word_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE4i7s-0zgvh",
        "outputId": "861958cd-0cf5-4298-a04e-de2e0b0639a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 937ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the predicted next word\n",
        "print(predicted_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBF9CViezuLF",
        "outputId": "21ef3af4-0806-4a0c-ef9a-f8bfabcca149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "little\n"
          ]
        }
      ]
    }
  ]
}